{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Science Design Pattern for Student Drop Out\"\n",
    "author: \"Microsoft\"\n",
    "output: \n",
    "    rmarkdown::html_vignette:\n",
    "        toc: true\n",
    "\n",
    "vignette: >\n",
    "  %\\VignetteIndexEntry{Vignette Title}\n",
    "  %\\VignetteEngine{knitr::rmarkdown}\n",
    "  %\\VignetteEncoding{UTF-8}\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "knitr::opts_chunk$set(fig.width = 6,\n",
    "                      fig.height = 4,\n",
    "                      fig.align='center',\n",
    "                      dev = \"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducation\n",
    "\n",
    "Welcome to the Data Science Design Pattern for Student Drop Out. This pattern provides a starting point for the data scientist exploring a new dataset. By no means is it the end point of the data science journey. The pattern is under regular revision and improvement and is provided as is. \n",
    "\n",
    "We now introduce a generic pattern for building multiple binary classification models using R.\n",
    "\n",
    "# Pre-configuration\n",
    "\n",
    "We load the R packages required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rattle: A free graphical interface for data mining with R.\n",
      "Version 4.1.0 Copyright (c) 2006-2015 Togaware Pty Ltd.\n",
      "Type 'rattle()' to shake, rattle, and roll your data.\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Attaching package: 'mlr'\n",
      "\n",
      "The following object is masked from 'package:MicrosoftML':\n",
      "\n",
      "    selectFeatures\n",
      "\n",
      "Loading required package: foreach\n",
      "Loading required package: doParallel\n",
      "Loading required package: iterators\n",
      "Loading required package: parallel\n",
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "Loading required package: grid\n",
      "Loading required package: mvtnorm\n",
      "Loading required package: modeltools\n",
      "Loading required package: stats4\n",
      "Loading required package: strucchange\n",
      "Loading required package: zoo\n",
      "\n",
      "Attaching package: 'zoo'\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Loading required package: sandwich\n",
      "\n",
      "Attaching package: 'e1071'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    impute\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: 'ggplot2'\n",
      "\n",
      "The following object is masked from 'package:randomForest':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    train\n",
      "\n",
      "Loading required package: gplots\n",
      "\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "\n",
      "Attaching package: 'ROCR'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    performance\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "Attaching package: 'pROC'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# R SETUP\n",
    "\n",
    "# Load required packages from local library into R.\n",
    "\n",
    "library(magrittr)     # Data pipelines: %>% %T>% %<>%.\n",
    "library(stringi)      # String operator: %s+%.\n",
    "library(rattle)       # Evaluate using riskchart().\n",
    "library(mlr)          # Dependency of unbalanced.\n",
    "library(unbalanced)   # Resampling using ubSMOTE.\n",
    "library(rpart)        # Model: decision tree.\n",
    "library(rpart.plot)   # Draw fancyRpartPlot().\n",
    "library(randomForest) # Model: random forest.\n",
    "library(ada)          # Model: ada boosting.\n",
    "library(party)        # Model: ctree and cforest.\n",
    "library(e1071)        # Model: support vector machine.\n",
    "library(nnet)         # Model: neural network.\n",
    "library(Matrix)       # Construct a Matrix of a class that inherits from Matrix.\n",
    "library(caret)        # Tune model hyper-parameters.\n",
    "library(xgboost)      # Model: extreme gradiant boosting.\n",
    "library(Ckmeans.1d.dp)# Plot feature importance using xgb.plot.importance.\n",
    "library(DiagrammeR)   # Plot xgboost tree using xgb.plot.tree.\n",
    "library(ROCR)         # Use prediction() for evaluation.\n",
    "library(pROC)         # Use auc() for evaluation. \n",
    "library(ggplot2)      # Visually evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.4: Re-load Dataset\n",
    "\n",
    "In the Data template we loaded the studentDropIndia dataset, processed it, and saved it to file. Here we re-load the dataset and review its contents. In addition, we define some support functions for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"data/studentDropIndia_20161215.RData\"\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# DATA INGESTION\n",
    "\n",
    "# Identify the dataset.\n",
    "\n",
    "dsname <- \"studentDropIndia\"\n",
    "\n",
    "# We define some support functions that we often find useful.\n",
    "\n",
    "evaluateModel <- function(data, observed, predicted) \n",
    "{ \n",
    "  # Calculate the confusion matrix\n",
    "  \n",
    "  confusion <- table(data[[observed]], data[[predicted]], dnn=c(\"Observed\", \"Predicted\"))\n",
    "  confusion %>% print()\n",
    "  \n",
    "  # Calculate the performance metrics\n",
    "  \n",
    "  tp <- confusion[rownames(confusion) == 1, colnames(confusion) == 1]\n",
    "  fn <- confusion[rownames(confusion) == 1, colnames(confusion) == 0]\n",
    "  fp <- confusion[rownames(confusion) == 0, colnames(confusion) == 1]\n",
    "  tn <- confusion[rownames(confusion) == 0, colnames(confusion) == 0]\n",
    "  \n",
    "  accuracy <- (tp + tn) / (tp + fn + fp + tn)\n",
    "  precision <- tp / (tp + fp)\n",
    "  recall <- tp / (tp + fn)\n",
    "  fscore <- 2 * (precision * recall) / (precision + recall)\n",
    "  \n",
    "  # Construct the vector of performance metrics\n",
    "  \n",
    "  metrics <- c(\"Accuracy\" = accuracy,\n",
    "               \"Precision\" = precision,\n",
    "               \"Recall\" = recall,\n",
    "               \"F-Score\" = fscore)\n",
    "  \n",
    "  # Return the vector of performance metrics\n",
    "  \n",
    "  return(metrics)\n",
    "}\n",
    "\n",
    "rocChart <- function(pr, target)\n",
    "{\n",
    "  # Calculate the true positive and the false positive rates.\n",
    "  \n",
    "  rates <- pr %>%\n",
    "    prediction(target) %>%\n",
    "    performance(\"tpr\", \"fpr\")\n",
    "  \n",
    "  # Calulcate the AUC.\n",
    "  \n",
    "  auc <- pr %>%\n",
    "    prediction(target) %>%\n",
    "    performance(\"auc\") %>%\n",
    "    attr(\"y.values\") %>%\n",
    "    extract2(1)\n",
    "  \n",
    "  # Construct the plot.\n",
    "  \n",
    "  pl <- data.frame(tpr=attr(rates, \"y.values\")[[1]], \n",
    "                   fpr=attr(rates, \"x.values\")[[1]]) %>%\n",
    "    ggplot(aes(fpr, tpr)) +\n",
    "    geom_line() +\n",
    "    annotate(\"text\", x=0.875, y=0.125, vjust=0,\n",
    "             label=paste(\"AUC =\", round(100*auc, 2)), \n",
    "             family=\"xkcd\") +\n",
    "    xlab(\"False Positive Rate (1-Specificity)\") +\n",
    "    ylab(\"True Positive Rate (Sensitivity)\")\n",
    "  \n",
    "  # Return the plot object.\n",
    "  \n",
    "  return(pl)\n",
    "}\n",
    "\n",
    "# Identify the dataset to load.\n",
    "\n",
    "fpath  <- \"data\"\n",
    "dsdate <- \"_\" %s+% \"20161215\"\n",
    "\n",
    "# Filename of the saved dataset.\n",
    "\n",
    "dsrdata <-\n",
    "  file.path(fpath, dsname %s+% dsdate %s+% \".RData\") %T>% \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"ds\"     \"dsname\" \"dspath\" \"dsdate\" \"nobs\"   \"vars\"   \"target\" \"id\"    \n",
      " [9] \"ignore\" \"omit\"   \"inputi\" \"inputs\" \"numi\"   \"numc\"   \"cati\"   \"catc\"  \n"
     ]
    }
   ],
   "source": [
    "# Load the R objects from file and list them.\n",
    "\n",
    "load(dsrdata) %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'studentDropIndia'"
      ],
      "text/latex": [
       "'studentDropIndia'"
      ],
      "text/markdown": [
       "'studentDropIndia'"
      ],
      "text/plain": [
       "[1] \"studentDropIndia\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'C:/Demo/EducationAnalytics/Data/studentDropIndia_20161215.csv'"
      ],
      "text/latex": [
       "'C:/Demo/EducationAnalytics/Data/studentDropIndia\\_20161215.csv'"
      ],
      "text/markdown": [
       "'C:/Demo/EducationAnalytics/Data/studentDropIndia_20161215.csv'"
      ],
      "text/plain": [
       "[1] \"C:/Demo/EducationAnalytics/Data/studentDropIndia_20161215.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'_20161215'"
      ],
      "text/latex": [
       "'\\_20161215'"
      ],
      "text/markdown": [
       "'_20161215'"
      ],
      "text/plain": [
       "[1] \"_20161215\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "19100"
      ],
      "text/latex": [
       "19100"
      ],
      "text/markdown": [
       "19100"
      ],
      "text/plain": [
       "[1] 19100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'continue_drop'</li>\n",
       "\t<li>'gender'</li>\n",
       "\t<li>'caste'</li>\n",
       "\t<li>'mathematics_marks'</li>\n",
       "\t<li>'english_marks'</li>\n",
       "\t<li>'science_marks'</li>\n",
       "\t<li>'science_teacher'</li>\n",
       "\t<li>'languages_teacher'</li>\n",
       "\t<li>'guardian'</li>\n",
       "\t<li>'internet'</li>\n",
       "\t<li>'total_students'</li>\n",
       "\t<li>'total_toilets'</li>\n",
       "\t<li>'establishment_year'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'continue\\_drop'\n",
       "\\item 'gender'\n",
       "\\item 'caste'\n",
       "\\item 'mathematics\\_marks'\n",
       "\\item 'english\\_marks'\n",
       "\\item 'science\\_marks'\n",
       "\\item 'science\\_teacher'\n",
       "\\item 'languages\\_teacher'\n",
       "\\item 'guardian'\n",
       "\\item 'internet'\n",
       "\\item 'total\\_students'\n",
       "\\item 'total\\_toilets'\n",
       "\\item 'establishment\\_year'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'continue_drop'\n",
       "2. 'gender'\n",
       "3. 'caste'\n",
       "4. 'mathematics_marks'\n",
       "5. 'english_marks'\n",
       "6. 'science_marks'\n",
       "7. 'science_teacher'\n",
       "8. 'languages_teacher'\n",
       "9. 'guardian'\n",
       "10. 'internet'\n",
       "11. 'total_students'\n",
       "12. 'total_toilets'\n",
       "13. 'establishment_year'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"continue_drop\"      \"gender\"             \"caste\"             \n",
       " [4] \"mathematics_marks\"  \"english_marks\"      \"science_marks\"     \n",
       " [7] \"science_teacher\"    \"languages_teacher\"  \"guardian\"          \n",
       "[10] \"internet\"           \"total_students\"     \"total_toilets\"     \n",
       "[13] \"establishment_year\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'continue_drop'"
      ],
      "text/latex": [
       "'continue\\_drop'"
      ],
      "text/markdown": [
       "'continue_drop'"
      ],
      "text/plain": [
       "[1] \"continue_drop\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'student_id'</li>\n",
       "\t<li>'school_id'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'student\\_id'\n",
       "\\item 'school\\_id'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'student_id'\n",
       "2. 'school_id'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"student_id\" \"school_id\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'student_id'</li>\n",
       "\t<li>'school_id'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'student\\_id'\n",
       "\\item 'school\\_id'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'student_id'\n",
       "2. 'school_id'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"student_id\" \"school_id\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the metadata.\n",
    "\n",
    "dsname\n",
    "dspath\n",
    "dsdate\n",
    "nobs\n",
    "vars\n",
    "target\n",
    "id\n",
    "ignore\n",
    "omit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.5: Prepare - Formula to Describe the Goal\n",
    "\n",
    "We continue on from the Data module where we had Steps 1, 2, and 3 and the beginnings of Step 4 of a data mining process.\n",
    "\n",
    "The next step is to describe the model to be built by way of writing a formula to capture our intent. The formula describes the model to be built as being constructed to predict the target variable based on the other (suitable) variables available in the dataset. The notation used to express this is to name the target (continue_drop), followed by a tilde (~) followed by a period (.) to represent all other variables (these variables will be listed in vars in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue_drop ~ gender + caste + mathematics_marks + english_marks + \n",
      "    science_marks + science_teacher + languages_teacher + guardian + \n",
      "    internet + total_students + total_toilets + establishment_year\n",
      "<environment: 0x00000000299568a8>\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# PREPARE FOR MODELLING\n",
    "\n",
    "# Formula for modelling.\n",
    "\n",
    "form <- ds[vars] %>% formula() %T>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common methodology for model building is to randomly partition the available data into a training dataset and testing dataset. We sometimes also introducing a third dataset called the validation dataset, used during the building of the model, but for now we will use just the two.\n",
    "\n",
    "First we (optionally) initiate the random number sequence with a randomly selected seed, and report what the seed is so that we could repeat the experiments presented here if required. For consistency in this module we use a particular seed of 123.\n",
    "\n",
    "Next we partition the dataset into two subsets. The first is a 70% random sample for building the model (the training dataset) and the second is the remainder, used to evaluate the performance of the model (the testing dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 13370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5493</li>\n",
       "\t<li>15056</li>\n",
       "\t<li>7811</li>\n",
       "\t<li>16863</li>\n",
       "\t<li>17960</li>\n",
       "\t<li>870</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5493\n",
       "\\item 15056\n",
       "\\item 7811\n",
       "\\item 16863\n",
       "\\item 17960\n",
       "\\item 870\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5493\n",
       "2. 15056\n",
       "3. 7811\n",
       "4. 16863\n",
       "5. 17960\n",
       "6. 870\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  5493 15056  7811 16863 17960   870"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 5730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>6</li>\n",
       "\t<li>15</li>\n",
       "\t<li>16</li>\n",
       "\t<li>17</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 6\n",
       "\\item 15\n",
       "\\item 16\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 3\n",
       "3. 6\n",
       "4. 15\n",
       "5. 16\n",
       "6. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  2  3  6 15 16 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise random numbers for repeatable results.\n",
    "\n",
    "seed <- 123\n",
    "set.seed(seed)\n",
    "\n",
    "# Partition the full dataset into two.\n",
    "\n",
    "train <- \n",
    "  sample(nobs, 0.70*nobs) %T>% \n",
    "  {length(.) %>% print()}\n",
    "\n",
    "head(train)\n",
    "\n",
    "test <- \n",
    "  seq_len(nobs) %>%\n",
    "  setdiff(train) %T>%\n",
    "  {length(.) %>% print()}\n",
    "\n",
    "head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Resampling - Rebalancing the Proportion of Minority over Majority (Optional)\n",
    "\n",
    "Since the proportion of minority class (student dropping-out) is around 5% among the whole dataset, we here implement the SMOTE on the training dataset by using the function ubSMOTE from the R package “unbalanced”. This yields a dropping-out proportion of 23% among all the training data. By using the training dataset after SMOTE as the modeling input, we can greatly improve the model performance, especially when applying some of the algorithms not suitable for unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        0         1 \n",
       "0.7692308 0.2307692 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebalance the training dataset.\n",
    "\n",
    "traindata <- as.data.frame(ds[train, inputs])\n",
    "traintarget <- as.factor(as.numeric(as.data.frame(ds[train, target])[[1]])-1)\n",
    "\n",
    "smote <- ubSMOTE(X=traindata, Y=traintarget,\n",
    "                 perc.over=200, perc.under=500,\n",
    "                 k=3, verbose=TRUE) \n",
    "\n",
    "trainsmote <- cbind(smote$X, smote$Y)\n",
    "names(trainsmote)[names(trainsmote) == \"smote$Y\"] <- \"continue_drop\"\n",
    "\n",
    "traindata <- trainsmote\n",
    "\n",
    "# Check the dropping-out proportion\n",
    "\n",
    "table(traindata$continue_drop)/nrow(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.1: Build - Decision Tree Model\n",
    "\n",
    "The commonly used classification model builders include rpart() decision tree, randomForest() random forest, ada() stochastic boosting, ect. Now we build an rpart() decision tree, as a baseline model builder. Note that our models from now on are all built on the original training dataset in the purpose of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   0.97    0.12    1.13 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "n= 13370 \n",
       "\n",
       "node), split, n, loss, yval, (yprob)\n",
       "      * denotes terminal node\n",
       "\n",
       " 1) root 13370 645 continue (0.95175767 0.04824233)  \n",
       "   2) english_marks< 0.9975 13334 609 continue (0.95432728 0.04567272)  \n",
       "     4) science_teacher< 5.5 9625 244 continue (0.97464935 0.02535065) *\n",
       "     5) science_teacher>=5.5 3709 365 continue (0.90159073 0.09840927)  \n",
       "      10) english_marks>=0.228 3671 327 continue (0.91092345 0.08907655) *\n",
       "      11) english_marks< 0.228 38   0 drop (0.00000000 1.00000000) *\n",
       "   3) english_marks>=0.9975 36   0 drop (0.00000000 1.00000000) *"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: rpart\n",
    "\n",
    "ctrl <- rpart.control(maxdepth=3)\n",
    "system.time(m.rp <- rpart(form, ds[train, vars], control=ctrl))\n",
    "m.rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Record the type of the model for later use.\n",
    "\n",
    "mtype <- \"rpart\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in as.POSIXlt.POSIXct(x, tz):\n",
      "\"unable to identify current timezone 'C':\n",
      "please set environment variable 'TZ'\""
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAmVBMVEUAAAAgNEEjOyMrR1cv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\nQmCC",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fancyRpartPlot(m.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.2: Evaluate - Decision Tree Model\n",
    "\n",
    "As we have noted though, performing any evaluation on the training dataset provides a biased estimate of the actual performance. We must instead evaluate the performance of our models on a previously unseen dataset (at least unseen by the algorithm building the model).\n",
    "\n",
    "So we now evaluate the model performance on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>continue_drop</th><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>rpart_prediction</th><th scope=col>rpart_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.290     </td><td>0.512     </td><td>0.290     </td><td>4         </td><td> 7        </td><td>mother    </td><td>true      </td><td>356       </td><td>14        </td><td>1943      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>oc        </td><td>0.602     </td><td>0.666     </td><td>0.602     </td><td>4         </td><td> 2        </td><td>mother    </td><td>false     </td><td>179       </td><td> 8        </td><td>1955      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.594     </td><td>0.519     </td><td>0.594     </td><td>4         </td><td> 8        </td><td>mother    </td><td>true      </td><td>335       </td><td>43        </td><td>1916      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.461     </td><td>0.524     </td><td>0.461     </td><td>0         </td><td> 3        </td><td>mother    </td><td>true      </td><td>469       </td><td>14        </td><td>1905      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>oc        </td><td>0.742     </td><td>0.672     </td><td>0.742     </td><td>3         </td><td>12        </td><td>mother    </td><td>true      </td><td>132       </td><td>14        </td><td>1996      </td><td>0         </td><td>0.02535065</td></tr>\n",
       "\t<tr><td>drop      </td><td>f         </td><td>bc        </td><td>0.503     </td><td>0.523     </td><td>0.503     </td><td>9         </td><td> 0        </td><td>father    </td><td>true      </td><td>397       </td><td> 5        </td><td>1950      </td><td>0         </td><td>0.08907655</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " continue\\_drop & gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & rpart\\_prediction & rpart\\_probability\\\\\n",
       "\\hline\n",
       "\t continue   & f          & bc         & 0.290      & 0.512      & 0.290      & 4          &  7         & mother     & true       & 356        & 14         & 1943       & 0          & 0.02535065\\\\\n",
       "\t continue   & f          & oc         & 0.602      & 0.666      & 0.602      & 4          &  2         & mother     & false      & 179        &  8         & 1955       & 0          & 0.02535065\\\\\n",
       "\t continue   & f          & bc         & 0.594      & 0.519      & 0.594      & 4          &  8         & mother     & true       & 335        & 43         & 1916       & 0          & 0.02535065\\\\\n",
       "\t continue   & f          & bc         & 0.461      & 0.524      & 0.461      & 0          &  3         & mother     & true       & 469        & 14         & 1905       & 0          & 0.02535065\\\\\n",
       "\t continue   & f          & oc         & 0.742      & 0.672      & 0.742      & 3          & 12         & mother     & true       & 132        & 14         & 1996       & 0          & 0.02535065\\\\\n",
       "\t drop       & f          & bc         & 0.503      & 0.523      & 0.503      & 9          &  0         & father     & true       & 397        &  5         & 1950       & 0          & 0.08907655\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "continue_drop | gender | caste | mathematics_marks | english_marks | science_marks | science_teacher | languages_teacher | guardian | internet | total_students | total_toilets | establishment_year | rpart_prediction | rpart_probability | \n",
       "|---|---|---|---|---|---|\n",
       "| continue   | f          | bc         | 0.290      | 0.512      | 0.290      | 4          |  7         | mother     | true       | 356        | 14         | 1943       | 0          | 0.02535065 | \n",
       "| continue   | f          | oc         | 0.602      | 0.666      | 0.602      | 4          |  2         | mother     | false      | 179        |  8         | 1955       | 0          | 0.02535065 | \n",
       "| continue   | f          | bc         | 0.594      | 0.519      | 0.594      | 4          |  8         | mother     | true       | 335        | 43         | 1916       | 0          | 0.02535065 | \n",
       "| continue   | f          | bc         | 0.461      | 0.524      | 0.461      | 0          |  3         | mother     | true       | 469        | 14         | 1905       | 0          | 0.02535065 | \n",
       "| continue   | f          | oc         | 0.742      | 0.672      | 0.742      | 3          | 12         | mother     | true       | 132        | 14         | 1996       | 0          | 0.02535065 | \n",
       "| drop       | f          | bc         | 0.503      | 0.523      | 0.503      | 9          |  0         | father     | true       | 397        |  5         | 1950       | 0          | 0.08907655 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  continue_drop gender caste mathematics_marks english_marks science_marks\n",
       "1 continue      f      bc    0.290             0.512         0.290        \n",
       "2 continue      f      oc    0.602             0.666         0.602        \n",
       "3 continue      f      bc    0.594             0.519         0.594        \n",
       "4 continue      f      bc    0.461             0.524         0.461        \n",
       "5 continue      f      oc    0.742             0.672         0.742        \n",
       "6 drop          f      bc    0.503             0.523         0.503        \n",
       "  science_teacher languages_teacher guardian internet total_students\n",
       "1 4                7                mother   true     356           \n",
       "2 4                2                mother   false    179           \n",
       "3 4                8                mother   true     335           \n",
       "4 0                3                mother   true     469           \n",
       "5 3               12                mother   true     132           \n",
       "6 9                0                father   true     397           \n",
       "  total_toilets establishment_year rpart_prediction rpart_probability\n",
       "1 14            1943               0                0.02535065       \n",
       "2  8            1955               0                0.02535065       \n",
       "3 43            1916               0                0.02535065       \n",
       "4 14            1905               0                0.02535065       \n",
       "5 14            1996               0                0.02535065       \n",
       "6  5            1950               0                0.08907655       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.rp, ds[test, vars], type=\"prob\")\n",
    "threshold <- 0.5\n",
    "rpart_probability <- predictions[, 2]\n",
    "rpart_prediction <- ifelse(rpart_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], rpart_prediction, rpart_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5475    0\n",
      "       1  229   26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.960034904013962</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>0.101960784313725</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>0.185053380782918</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.960034904013962\n",
       "\\item[Precision] 1\n",
       "\\item[Recall] 0.101960784313725\n",
       "\\item[F-Score] 0.185053380782918\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.960034904013962Precision\n",
       ":   1Recall\n",
       ":   0.101960784313725F-Score\n",
       ":   0.185053380782918\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "0.9600349 1.0000000 0.1019608 0.1850534 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.rp <- evaluateModel(data=pred,\n",
    "                            observed=\"continue_drop\",\n",
    "                            predicted=\"rpart_prediction\")\n",
    "metrics.rp\n",
    "\n",
    "rocChart(pr=pred$rpart_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.3: Compare - Multiple Models using Experiment\n",
    "\n",
    "We can repeat the modelling multiple times, randomly selecting different datasets for training, to get an estimate \n",
    "of the actual expected performance and variation we see in the performance. The helper function experi() can be used \n",
    "to assist us here. It is available as http://onepager.togaware.com/experi.R and we show some of the coding of experi() \n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the function experi()\n",
    "\n",
    "experi <- function(form, ds, dsname, target, modeller, details=\"\",\n",
    "                   n=100, control=NULL,\n",
    "                   keep=FALSE, # Keep the last model built.\n",
    "                   prob=\"prob\",   \n",
    "                   class=\"class\",\n",
    "                   log=\"experi.log\")\n",
    "{\n",
    " suppressPackageStartupMessages(require(pROC))\n",
    "  \n",
    " user <- Sys.getenv(\"LOGNAME\")\n",
    " node <- Sys.info()[[\"nodename\"]]\n",
    " \n",
    " wsrpart.model <- modeller==\"wsrpart\"\n",
    " \n",
    " numclass <- length(levels(ds[,target]))\n",
    " \n",
    " start.time <- proc.time()\n",
    " \n",
    " seeds <- cors <- strs <- aucs <- accs <- NULL\n",
    " for (i in seq_len(n))\n",
    "{\n",
    " loop.time <- proc.time()\n",
    " \n",
    " seeds <- c(seeds, seed <- sample(1:1000000, 1))\n",
    " set.seed(seed)\n",
    " \n",
    "....\n",
    "\n",
    " result[-c(1:7)] <- round(result[-c(1:7)], 2)\n",
    " row.names(result) <- NULL\n",
    " if (keep)\n",
    " {\n",
    "  if (numclass==2)\n",
    "  {\n",
    "   attr(result, \"pr\") <- pr\n",
    "   attr(result, \"test\") <- test\n",
    "  }\n",
    "  attr(result, \"model\") <- model\n",
    " }\n",
    "}\n",
    "return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the experiments using the algorihtms rpart (Therneau and Atkinson, 2014), randomForest (Breiman et al., 2012),\n",
    "ada (Culp et al., 2012), ctree() from party (Hothorn et al., 2013). In such way, we can conveniently implement those \n",
    "models and compare their performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Source experi.R \n",
    "# \n",
    "# source(\"http://onepager.togaware.com/experi.R\")\n",
    "# \n",
    "# # Set the times of loops\n",
    "# \n",
    "# n <- 10\n",
    "# \n",
    "# # Run experiments\n",
    "# \n",
    "# ex.rp <- experi(form, ds[vars], dsname, target, \"rpart\", \"1\", n=n, keep=TRUE)\n",
    "# ex.rf <- experi(form, ds[vars], dsname, target, \"randomForest\", \"500\", n=n, keep=TRUE,         control=list(na.action=na.omit))\n",
    "# ex.ad <- experi(form, ds[vars], dsname, target, \"ada\", \"50\", n=n, keep=TRUE)\n",
    "# ex.ct <- experi(form, ds[vars], dsname, target, \"ctree\", \"1\", n=n, keep=TRUE)\n",
    "# \n",
    "# # Compare results\n",
    "# \n",
    "# results <- rbind(ex.rp, ex.rf, ex.ad, ex.ct)\n",
    "# rownames(results) <- results$modeller\n",
    "# results$modeller <- NULL\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.1: Other Models - Support Vector Machine Model\n",
    "\n",
    "Except for the above commonly used binary classification models, we could also try some more advanced models, for instance, svm(), support vector machine, nnet(), neural network, xgboost(), extreme gradient boosting, ect. We firstly build a svm() support vector machine model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    user   system  elapsed \n",
       "12313.95    20.13 12365.94 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.034181\n"
     ]
    }
   ],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    " system.time({\n",
    " m.svm.cv <- tune.svm(form,\n",
    "                      data=ds[train, vars],\n",
    "                      gamma=2^(-1:1),\n",
    "                      cost=2^(2:4),\n",
    "                      type=\"C-classification\",\n",
    "                      probability=TRUE,\n",
    "                      scale=FALSE)\n",
    " })\n",
    "\n",
    "print(m.svm.cv$best.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       " 180.23    0.19  180.45 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: svm\n",
    "\n",
    "system.time({\n",
    "  m.svm <- svm(form, \n",
    "               data=ds[train, vars], \n",
    "               #gamma=0.1,\n",
    "               #cost=0.1,\n",
    "               gamma=m.svm.cv$best.parameters[1], \n",
    "               cost=m.svm.cv$best.parameters[2],\n",
    "               type=\"C-classification\",\n",
    "               probability = TRUE,\n",
    "               scale = FALSE)\n",
    "})\n",
    "\n",
    "# Check the model information\n",
    "\n",
    "m.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>continue_drop</th><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>svm_prediction</th><th scope=col>svm_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.290     </td><td>0.512     </td><td>0.290     </td><td>4         </td><td> 7        </td><td>mother    </td><td>true      </td><td>356       </td><td>14        </td><td>1943      </td><td>0         </td><td>0.03416375</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>oc        </td><td>0.602     </td><td>0.666     </td><td>0.602     </td><td>4         </td><td> 2        </td><td>mother    </td><td>false     </td><td>179       </td><td> 8        </td><td>1955      </td><td>0         </td><td>0.03744888</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.594     </td><td>0.519     </td><td>0.594     </td><td>4         </td><td> 8        </td><td>mother    </td><td>true      </td><td>335       </td><td>43        </td><td>1916      </td><td>0         </td><td>0.03462933</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>bc        </td><td>0.461     </td><td>0.524     </td><td>0.461     </td><td>0         </td><td> 3        </td><td>mother    </td><td>true      </td><td>469       </td><td>14        </td><td>1905      </td><td>0         </td><td>0.02757413</td></tr>\n",
       "\t<tr><td>continue  </td><td>f         </td><td>oc        </td><td>0.742     </td><td>0.672     </td><td>0.742     </td><td>3         </td><td>12        </td><td>mother    </td><td>true      </td><td>132       </td><td>14        </td><td>1996      </td><td>0         </td><td>0.03769413</td></tr>\n",
       "\t<tr><td>drop      </td><td>f         </td><td>bc        </td><td>0.503     </td><td>0.523     </td><td>0.503     </td><td>9         </td><td> 0        </td><td>father    </td><td>true      </td><td>397       </td><td> 5        </td><td>1950      </td><td>1         </td><td>0.94207574</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " continue\\_drop & gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & svm\\_prediction & svm\\_probability\\\\\n",
       "\\hline\n",
       "\t continue   & f          & bc         & 0.290      & 0.512      & 0.290      & 4          &  7         & mother     & true       & 356        & 14         & 1943       & 0          & 0.03416375\\\\\n",
       "\t continue   & f          & oc         & 0.602      & 0.666      & 0.602      & 4          &  2         & mother     & false      & 179        &  8         & 1955       & 0          & 0.03744888\\\\\n",
       "\t continue   & f          & bc         & 0.594      & 0.519      & 0.594      & 4          &  8         & mother     & true       & 335        & 43         & 1916       & 0          & 0.03462933\\\\\n",
       "\t continue   & f          & bc         & 0.461      & 0.524      & 0.461      & 0          &  3         & mother     & true       & 469        & 14         & 1905       & 0          & 0.02757413\\\\\n",
       "\t continue   & f          & oc         & 0.742      & 0.672      & 0.742      & 3          & 12         & mother     & true       & 132        & 14         & 1996       & 0          & 0.03769413\\\\\n",
       "\t drop       & f          & bc         & 0.503      & 0.523      & 0.503      & 9          &  0         & father     & true       & 397        &  5         & 1950       & 1          & 0.94207574\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "continue_drop | gender | caste | mathematics_marks | english_marks | science_marks | science_teacher | languages_teacher | guardian | internet | total_students | total_toilets | establishment_year | svm_prediction | svm_probability | \n",
       "|---|---|---|---|---|---|\n",
       "| continue   | f          | bc         | 0.290      | 0.512      | 0.290      | 4          |  7         | mother     | true       | 356        | 14         | 1943       | 0          | 0.03416375 | \n",
       "| continue   | f          | oc         | 0.602      | 0.666      | 0.602      | 4          |  2         | mother     | false      | 179        |  8         | 1955       | 0          | 0.03744888 | \n",
       "| continue   | f          | bc         | 0.594      | 0.519      | 0.594      | 4          |  8         | mother     | true       | 335        | 43         | 1916       | 0          | 0.03462933 | \n",
       "| continue   | f          | bc         | 0.461      | 0.524      | 0.461      | 0          |  3         | mother     | true       | 469        | 14         | 1905       | 0          | 0.02757413 | \n",
       "| continue   | f          | oc         | 0.742      | 0.672      | 0.742      | 3          | 12         | mother     | true       | 132        | 14         | 1996       | 0          | 0.03769413 | \n",
       "| drop       | f          | bc         | 0.503      | 0.523      | 0.503      | 9          |  0         | father     | true       | 397        |  5         | 1950       | 1          | 0.94207574 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  continue_drop gender caste mathematics_marks english_marks science_marks\n",
       "1 continue      f      bc    0.290             0.512         0.290        \n",
       "2 continue      f      oc    0.602             0.666         0.602        \n",
       "3 continue      f      bc    0.594             0.519         0.594        \n",
       "4 continue      f      bc    0.461             0.524         0.461        \n",
       "5 continue      f      oc    0.742             0.672         0.742        \n",
       "6 drop          f      bc    0.503             0.523         0.503        \n",
       "  science_teacher languages_teacher guardian internet total_students\n",
       "1 4                7                mother   true     356           \n",
       "2 4                2                mother   false    179           \n",
       "3 4                8                mother   true     335           \n",
       "4 0                3                mother   true     469           \n",
       "5 3               12                mother   true     132           \n",
       "6 9                0                father   true     397           \n",
       "  total_toilets establishment_year svm_prediction svm_probability\n",
       "1 14            1943               0              0.03416375     \n",
       "2  8            1955               0              0.03744888     \n",
       "3 43            1916               0              0.03462933     \n",
       "4 14            1905               0              0.02757413     \n",
       "5 14            1996               0              0.03769413     \n",
       "6  5            1950               1              0.94207574     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model \n",
    "\n",
    "predictions <- predict(m.svm, ds[test, vars], probability=TRUE)\n",
    "threshold <- 0.5\n",
    "svm_probability <- attr(predictions, 'probabilities')[, 2]\n",
    "svm_prediction <- ifelse(svm_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], svm_prediction, svm_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5461   14\n",
      "       1  174   81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.967190226876091</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>0.852631578947368</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>0.317647058823529</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>0.462857142857143</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.967190226876091\n",
       "\\item[Precision] 0.852631578947368\n",
       "\\item[Recall] 0.317647058823529\n",
       "\\item[F-Score] 0.462857142857143\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.967190226876091Precision\n",
       ":   0.852631578947368Recall\n",
       ":   0.317647058823529F-Score\n",
       ":   0.462857142857143\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "0.9671902 0.8526316 0.3176471 0.4628571 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.svm <- evaluateModel(data=pred,\n",
    "                              observed=\"continue_drop\",\n",
    "                              predicted=\"svm_prediction\")\n",
    "metrics.svm\n",
    "\n",
    "rocChart(pr=pred$svm_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.2: Other Models - Neural Network Model\n",
    "\n",
    "Next we build a nnet(), neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "3816.33    3.90 3822.14 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.02969334\n"
     ]
    }
   ],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    "system.time({\n",
    "m.nnet.cv <- tune.nnet(form, \n",
    "                       data=ds[train, vars], \n",
    "                       size=c(2, 4, 6, 8, 10), \n",
    "                       decay=5*10^(-5:-1), \n",
    "                       rang=0.1,\n",
    "                       maxit=200)\n",
    "})\n",
    "\n",
    "print(m.nnet.cv$best.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  109\n",
      "initial  value 8795.635722 \n",
      "iter  10 value 2584.626927\n",
      "iter  20 value 2584.251558\n",
      "iter  30 value 2579.904241\n",
      "iter  40 value 2551.472270\n",
      "iter  50 value 2438.169621\n",
      "iter  60 value 2245.353974\n",
      "iter  70 value 2181.523202\n",
      "iter  80 value 2079.203645\n",
      "iter  90 value 1844.057296\n",
      "iter 100 value 1736.034111\n",
      "iter 110 value 1722.882974\n",
      "iter 120 value 1637.740645\n",
      "iter 130 value 1447.625951\n",
      "iter 140 value 1268.792633\n",
      "iter 150 value 1003.792683\n",
      "iter 160 value 822.964306\n",
      "iter 170 value 720.855650\n",
      "iter 180 value 677.623554\n",
      "iter 190 value 668.045871\n",
      "iter 200 value 636.599741\n",
      "final  value 636.599741 \n",
      "stopped after 200 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   7.35    0.02    7.38 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a 16-6-1 network with 109 weights\n",
       "inputs: genderm casteoc castesc castest mathematics_marks english_marks science_marks science_teacher languages_teacher guardianmixed guardianmother guardianother internettrue total_students total_toilets establishment_year \n",
       "output(s): continue_drop \n",
       "options were - entropy fitting  decay=0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: nnet\n",
    "\n",
    "system.time({\n",
    "  m.nnet <- nnet(formula=form,\n",
    "                 data=ds[train, vars],\n",
    "                 #size=10,\n",
    "                 #decay=5e-4,\n",
    "                 size=as.numeric(m.nnet.cv$best.parameters[1]), \n",
    "                 decay=as.numeric(m.nnet.cv$best.parameters[2]), \n",
    "                 rang=0.1,\n",
    "                 maxit=200)\n",
    "})\n",
    "\n",
    "# Check the model information\n",
    "\n",
    "m.nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>continue_drop</th><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>nnet_prediction</th><th scope=col>nnet_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>continue    </td><td>f           </td><td>bc          </td><td>0.290       </td><td>0.512       </td><td>0.290       </td><td>4           </td><td> 7          </td><td>mother      </td><td>true        </td><td>356         </td><td>14          </td><td>1943        </td><td>0           </td><td>2.230320e-02</td></tr>\n",
       "\t<tr><td>continue    </td><td>f           </td><td>oc          </td><td>0.602       </td><td>0.666       </td><td>0.602       </td><td>4           </td><td> 2          </td><td>mother      </td><td>false       </td><td>179         </td><td> 8          </td><td>1955        </td><td>0           </td><td>2.911806e-05</td></tr>\n",
       "\t<tr><td>continue    </td><td>f           </td><td>bc          </td><td>0.594       </td><td>0.519       </td><td>0.594       </td><td>4           </td><td> 8          </td><td>mother      </td><td>true        </td><td>335         </td><td>43          </td><td>1916        </td><td>0           </td><td>2.894795e-05</td></tr>\n",
       "\t<tr><td>continue    </td><td>f           </td><td>bc          </td><td>0.461       </td><td>0.524       </td><td>0.461       </td><td>0           </td><td> 3          </td><td>mother      </td><td>true        </td><td>469         </td><td>14          </td><td>1905        </td><td>0           </td><td>1.020412e-05</td></tr>\n",
       "\t<tr><td>continue    </td><td>f           </td><td>oc          </td><td>0.742       </td><td>0.672       </td><td>0.742       </td><td>3           </td><td>12          </td><td>mother      </td><td>true        </td><td>132         </td><td>14          </td><td>1996        </td><td>0           </td><td>1.122212e-05</td></tr>\n",
       "\t<tr><td>drop        </td><td>f           </td><td>bc          </td><td>0.503       </td><td>0.523       </td><td>0.503       </td><td>9           </td><td> 0          </td><td>father      </td><td>true        </td><td>397         </td><td> 5          </td><td>1950        </td><td>1           </td><td>9.772464e-01</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " continue\\_drop & gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & nnet\\_prediction & nnet\\_probability\\\\\n",
       "\\hline\n",
       "\t continue     & f            & bc           & 0.290        & 0.512        & 0.290        & 4            &  7           & mother       & true         & 356          & 14           & 1943         & 0            & 2.230320e-02\\\\\n",
       "\t continue     & f            & oc           & 0.602        & 0.666        & 0.602        & 4            &  2           & mother       & false        & 179          &  8           & 1955         & 0            & 2.911806e-05\\\\\n",
       "\t continue     & f            & bc           & 0.594        & 0.519        & 0.594        & 4            &  8           & mother       & true         & 335          & 43           & 1916         & 0            & 2.894795e-05\\\\\n",
       "\t continue     & f            & bc           & 0.461        & 0.524        & 0.461        & 0            &  3           & mother       & true         & 469          & 14           & 1905         & 0            & 1.020412e-05\\\\\n",
       "\t continue     & f            & oc           & 0.742        & 0.672        & 0.742        & 3            & 12           & mother       & true         & 132          & 14           & 1996         & 0            & 1.122212e-05\\\\\n",
       "\t drop         & f            & bc           & 0.503        & 0.523        & 0.503        & 9            &  0           & father       & true         & 397          &  5           & 1950         & 1            & 9.772464e-01\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "continue_drop | gender | caste | mathematics_marks | english_marks | science_marks | science_teacher | languages_teacher | guardian | internet | total_students | total_toilets | establishment_year | nnet_prediction | nnet_probability | \n",
       "|---|---|---|---|---|---|\n",
       "| continue     | f            | bc           | 0.290        | 0.512        | 0.290        | 4            |  7           | mother       | true         | 356          | 14           | 1943         | 0            | 2.230320e-02 | \n",
       "| continue     | f            | oc           | 0.602        | 0.666        | 0.602        | 4            |  2           | mother       | false        | 179          |  8           | 1955         | 0            | 2.911806e-05 | \n",
       "| continue     | f            | bc           | 0.594        | 0.519        | 0.594        | 4            |  8           | mother       | true         | 335          | 43           | 1916         | 0            | 2.894795e-05 | \n",
       "| continue     | f            | bc           | 0.461        | 0.524        | 0.461        | 0            |  3           | mother       | true         | 469          | 14           | 1905         | 0            | 1.020412e-05 | \n",
       "| continue     | f            | oc           | 0.742        | 0.672        | 0.742        | 3            | 12           | mother       | true         | 132          | 14           | 1996         | 0            | 1.122212e-05 | \n",
       "| drop         | f            | bc           | 0.503        | 0.523        | 0.503        | 9            |  0           | father       | true         | 397          |  5           | 1950         | 1            | 9.772464e-01 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  continue_drop gender caste mathematics_marks english_marks science_marks\n",
       "1 continue      f      bc    0.290             0.512         0.290        \n",
       "2 continue      f      oc    0.602             0.666         0.602        \n",
       "3 continue      f      bc    0.594             0.519         0.594        \n",
       "4 continue      f      bc    0.461             0.524         0.461        \n",
       "5 continue      f      oc    0.742             0.672         0.742        \n",
       "6 drop          f      bc    0.503             0.523         0.503        \n",
       "  science_teacher languages_teacher guardian internet total_students\n",
       "1 4                7                mother   true     356           \n",
       "2 4                2                mother   false    179           \n",
       "3 4                8                mother   true     335           \n",
       "4 0                3                mother   true     469           \n",
       "5 3               12                mother   true     132           \n",
       "6 9                0                father   true     397           \n",
       "  total_toilets establishment_year nnet_prediction nnet_probability\n",
       "1 14            1943               0               2.230320e-02    \n",
       "2  8            1955               0               2.911806e-05    \n",
       "3 43            1916               0               2.894795e-05    \n",
       "4 14            1905               0               1.020412e-05    \n",
       "5 14            1996               0               1.122212e-05    \n",
       "6  5            1950               1               9.772464e-01    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.nnet, ds[test, vars], type=\"raw\")\n",
    "threshold <- 0.5\n",
    "nnet_probability <- predictions\n",
    "nnet_prediction <- ifelse(nnet_probability > threshold, 1, 0)\n",
    "pred <- cbind(ds[test, vars], nnet_prediction, nnet_probability)\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5474    1\n",
      "       1   31  224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.994415357766143</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>0.995555555555556</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>0.87843137254902</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>0.933333333333333</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.994415357766143\n",
       "\\item[Precision] 0.995555555555556\n",
       "\\item[Recall] 0.87843137254902\n",
       "\\item[F-Score] 0.933333333333333\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.994415357766143Precision\n",
       ":   0.995555555555556Recall\n",
       ":   0.87843137254902F-Score\n",
       ":   0.933333333333333\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "0.9944154 0.9955556 0.8784314 0.9333333 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nOCFR+iaG70MAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "pred$continue_drop <- as.numeric(pred$continue_drop)-1\n",
    "\n",
    "metrics.nnet <- evaluateModel(data=pred,\n",
    "                              observed=\"continue_drop\",\n",
    "                              predicted=\"nnet_prediction\")\n",
    "metrics.nnet\n",
    "\n",
    "rocChart(pr=pred$nnet_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.3: Other Models - Extreme Gradient Boosting Model\n",
    "\n",
    "Finally, we build a xgboost() extreme gradient boosting, as a specicial example, which performs well when dealing with unbalanced data. In our case, the proportion of student drop-out is around 5% in the original training dataset. Here we just use it as input to demonstrate the power of xgboost() in dealing with unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ data :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  .. ..@ i       : int [1:158037] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  .. ..@ p       : int [1:13] 0 13370 26740 40110 53480 66850 79090 91187 104557 117927 ...\n",
      "  .. ..@ Dim     : int [1:2] 13370 12\n",
      "  .. ..@ Dimnames:List of 2\n",
      "  .. .. ..$ : NULL\n",
      "  .. .. ..$ : chr [1:12] \"gender\" \"caste\" \"mathematics_marks\" \"english_marks\" ...\n",
      "  .. ..@ x       : num [1:158037] 1 1 1 1 1 1 1 2 2 2 ...\n",
      "  .. ..@ factors : list()\n",
      " $ label: num [1:13370] 0 0 0 0 0 1 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Re-structure the training data set\n",
    "\n",
    "traindata <- ds[train, inputs]\n",
    "\n",
    "traindata[, c(1:ncol(traindata))] <- sapply(traindata[, c(1:ncol(traindata))], as.numeric) \n",
    "ntrain <- as.matrix(traindata[ , c(1:ncol(traindata))])\n",
    "\n",
    "dtrain <- list()\n",
    "dtrain$data <- Matrix(ntrain, sparse=TRUE)\n",
    "dtrain$label <- as.numeric(as.data.frame(ds[train, target])[[1]]) - 1\n",
    "\n",
    "dtrain %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: plyr\n",
      "\n",
      "Attaching package: 'plyr'\n",
      "\n",
      "The following object is masked from 'package:modeltools':\n",
      "\n",
      "    empty\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eXtreme Gradient Boosting \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold) \n",
       "Summary of sample sizes: 10696, 10696, 10696, 10696, 10696 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  eta    max_depth  ROC        Sens       Spec      \n",
       "  1e-04   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-04   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-04   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-04  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-04  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-03   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-03   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-03   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-03  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-03  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-02   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-02   4         0.7739779  1.0000000  0.22015504\n",
       "  1e-02   8         0.9785562  0.9971709  0.66046512\n",
       "  1e-02  16         0.9974816  1.0000000  0.98139535\n",
       "  1e-02  32         0.9974816  1.0000000  0.98139535\n",
       "  1e-01   2         0.6868065  1.0000000  0.05581395\n",
       "  1e-01   4         0.7767530  1.0000000  0.22015504\n",
       "  1e-01   8         0.9871498  0.9995285  0.65581395\n",
       "  1e-01  16         1.0000000  1.0000000  0.96279070\n",
       "  1e-01  32         1.0000000  1.0000000  0.96279070\n",
       "  1e+00   2         0.7065927  1.0000000  0.09457364\n",
       "  1e+00   4         0.9152690  0.9993713  0.36899225\n",
       "  1e+00   8         0.9997807  0.9975639  1.00000000\n",
       "  1e+00  16         1.0000000  1.0000000  1.00000000\n",
       "  1e+00  32         1.0000000  1.0000000  1.00000000\n",
       "\n",
       "Tuning parameter 'nrounds' was held constant at a value of 2\n",
       "Tuning\n",
       "\n",
       "Tuning parameter 'min_child_weight' was held constant at a value of 1\n",
       "\n",
       "Tuning parameter 'subsample' was held constant at a value of 1\n",
       "ROC was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were nrounds = 2, max_depth = 16, eta\n",
       " = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1 and subsample = 1. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune hyper-parameters\n",
    "\n",
    "cv.ctrl <- trainControl(method=\"cv\",                     # specify resampling method to be cross-validation\n",
    "                        number=5,                        # set the number of folds to be 5\n",
    "                        verboseIter=FALSE,               # set to FALSE for not printing a training log\n",
    "                        returnData=FALSE,                # set to FALSE for not saving the data\n",
    "                        returnResamp=\"all\",              # save losses across all models\n",
    "                        classProbs=TRUE,                 # set to TRUE for class probabilities be computed for classification models \n",
    "                        summaryFunction=twoClassSummary, # specify a function AUC to compute performance metrics across resamples\n",
    "                        allowParallel=TRUE)              # use a parallel backend if it is available\n",
    "\n",
    "grid.xgb <- expand.grid(nrounds=2,\n",
    "                        max_depth=2^(1:5),\n",
    "                        eta=1*10^(-4:0),\n",
    "                        min_child_weight=1,\n",
    "                        colsample_bytree=1,\n",
    "                        subsample=1,\n",
    "                        gamma=0)\n",
    "\n",
    "set.seed(45)\n",
    "m.xgb.cv <-train(x=ntrain,\n",
    "                 y=as.data.frame(ds[train, target])[[1]],\n",
    "                 method=\"xgbTree\",\n",
    "                 trControl=cv.ctrl,\n",
    "                 tuneGrid=grid.xgb,\n",
    "                 verbose=TRUE,\n",
    "                 metric=\"ROC\",\n",
    "                 nthread =2)\n",
    "\n",
    "m.xgb.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.000000 \n",
      "[2]\ttrain-error:0.000000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   0.01    0.05    0.04 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 5.9 Kb \n",
       "call:\n",
       "  xgb.train(params = params, data = dtrain, nrounds = nrounds, \n",
       "    watchlist = watchlist, verbose = verbose, print_every_n = print_every_n, \n",
       "    early_stopping_rounds = early_stopping_rounds, maximize = maximize, \n",
       "    save_period = save_period, save_name = save_name, xgb_model = xgb_model, \n",
       "    callbacks = callbacks, max.depth = ..1, eta = ..2, min_child_weight = 1, \n",
       "    colsample_bytree = 1, subsample = 1, gamma = 0, nthread = 2, \n",
       "    objective = \"binary:logistic\")\n",
       "params (as set within xgb.train):\n",
       "  max_depth = \"16\", eta = \"0.1\", min_child_weight = \"1\", colsample_bytree = \"1\", subsample = \"1\", gamma = \"0\", nthread = \"2\", objective = \"binary:logistic\", silent = \"1\"\n",
       "xgb.attributes:\n",
       "  niter\n",
       "callbacks:\n",
       "  cb.print.evaluation(period = print_every_n)\n",
       "  cb.evaluation.log()\n",
       "  cb.save.model(save_period = save_period, save_name = save_name)\n",
       "niter: 2\n",
       "evaluation_log:\n",
       " iter train_error\n",
       "    1           0\n",
       "    2           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model: xgboost\n",
    "\n",
    "system.time({\n",
    "  m.xgb <- xgboost(data=dtrain$data, \n",
    "                   label=dtrain$label,\n",
    "                   nround=m.xgb.cv$bestTune[[1]], \n",
    "                   max.depth=m.xgb.cv$bestTune[[2]], \n",
    "                   eta=m.xgb.cv$bestTune[[3]], \n",
    "                   min_child_weight=1,\n",
    "                   colsample_bytree=1,\n",
    "                   subsample=1,\n",
    "                   gamma=0,\n",
    "                   nthread=2, \n",
    "                   objective=\"binary:logistic\")\n",
    "})\n",
    "\n",
    "m.xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature       Gain       Cover  Frequency\n",
      "1: mathematics_marks 0.30998281 0.147120885 0.27397260\n",
      "2:     english_marks 0.21674073 0.320301422 0.16438356\n",
      "3: languages_teacher 0.12209233 0.138141886 0.13698630\n",
      "4:          guardian 0.09762265 0.120764467 0.08219178\n",
      "5:             caste 0.09611334 0.078339736 0.15068493\n",
      "6:            gender 0.08452394 0.003929090 0.08219178\n",
      "7:   science_teacher 0.05576744 0.185562256 0.08219178\n",
      "8:          internet 0.01715675 0.005840258 0.02739726\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature importance\n",
    "\n",
    "importance <- xgb.importance(feature_names=dtrain$data@Dimnames[[2]], \n",
    "                             model=m.xgb)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAXFxcqKio8PDxN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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize feature importance\n",
    "\n",
    "xgb.plot.importance(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# Plot a boosted tree model\n",
    "\n",
    "xgb.plot.tree(dtrain$data@Dimnames[[2]], model=m.xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we score the model on testing dataset and evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ data :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  .. ..@ i       : int [1:67713] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  .. ..@ p       : int [1:13] 0 5730 11460 17190 22920 28650 33860 39063 44793 50523 ...\n",
      "  .. ..@ Dim     : int [1:2] 5730 12\n",
      "  .. ..@ Dimnames:List of 2\n",
      "  .. .. ..$ : NULL\n",
      "  .. .. ..$ : chr [1:12] \"gender\" \"caste\" \"mathematics_marks\" \"english_marks\" ...\n",
      "  .. ..@ x       : num [1:67713] 1 1 1 1 1 1 1 1 1 1 ...\n",
      "  .. ..@ factors : list()\n",
      " $ label: num [1:5730] 0 0 0 0 0 1 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# Re-structure the testing data set\n",
    "\n",
    "testdata <- ds[test, inputs]\n",
    "\n",
    "testdata[, c(1:ncol(traindata))] <- sapply(testdata[, c(1:ncol(traindata))], as.numeric) \n",
    "ntest <- as.matrix(testdata[, c(1:ncol(traindata))])\n",
    "\n",
    "dtest <- list()\n",
    "dtest$data <- Matrix(ntest, sparse=TRUE)\n",
    "dtest$label <- as.numeric(as.data.frame(ds[test, target])[[1]]) - 1\n",
    "\n",
    "dtest %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>caste</th><th scope=col>mathematics_marks</th><th scope=col>english_marks</th><th scope=col>science_marks</th><th scope=col>science_teacher</th><th scope=col>languages_teacher</th><th scope=col>guardian</th><th scope=col>internet</th><th scope=col>total_students</th><th scope=col>total_toilets</th><th scope=col>establishment_year</th><th scope=col>continue_drop</th><th scope=col>xgboost_prediction</th><th scope=col>xgboost_probability</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.290    </td><td>0.512    </td><td>0.290    </td><td>4        </td><td> 7       </td><td>3        </td><td>2        </td><td>356      </td><td>14       </td><td>1943     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>2        </td><td>0.602    </td><td>0.666    </td><td>0.602    </td><td>4        </td><td> 2       </td><td>3        </td><td>1        </td><td>179      </td><td> 8       </td><td>1955     </td><td>0        </td><td>0        </td><td>0.4060442</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.594    </td><td>0.519    </td><td>0.594    </td><td>4        </td><td> 8       </td><td>3        </td><td>2        </td><td>335      </td><td>43       </td><td>1916     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.461    </td><td>0.524    </td><td>0.461    </td><td>0        </td><td> 3       </td><td>3        </td><td>2        </td><td>469      </td><td>14       </td><td>1905     </td><td>0        </td><td>0        </td><td>0.4060442</td></tr>\n",
       "\t<tr><td>1        </td><td>2        </td><td>0.742    </td><td>0.672    </td><td>0.742    </td><td>3        </td><td>12       </td><td>3        </td><td>2        </td><td>132      </td><td>14       </td><td>1996     </td><td>0        </td><td>0        </td><td>0.4057302</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0.503    </td><td>0.523    </td><td>0.503    </td><td>9        </td><td> 0       </td><td>1        </td><td>2        </td><td>397      </td><td> 5       </td><td>1950     </td><td>1        </td><td>1        </td><td>0.5898832</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " gender & caste & mathematics\\_marks & english\\_marks & science\\_marks & science\\_teacher & languages\\_teacher & guardian & internet & total\\_students & total\\_toilets & establishment\\_year & continue\\_drop & xgboost\\_prediction & xgboost\\_probability\\\\\n",
       "\\hline\n",
       "\t 1         & 1         & 0.290     & 0.512     & 0.290     & 4         &  7        & 3         & 2         & 356       & 14        & 1943      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 2         & 0.602     & 0.666     & 0.602     & 4         &  2        & 3         & 1         & 179       &  8        & 1955      & 0         & 0         & 0.4060442\\\\\n",
       "\t 1         & 1         & 0.594     & 0.519     & 0.594     & 4         &  8        & 3         & 2         & 335       & 43        & 1916      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 1         & 0.461     & 0.524     & 0.461     & 0         &  3        & 3         & 2         & 469       & 14        & 1905      & 0         & 0         & 0.4060442\\\\\n",
       "\t 1         & 2         & 0.742     & 0.672     & 0.742     & 3         & 12        & 3         & 2         & 132       & 14        & 1996      & 0         & 0         & 0.4057302\\\\\n",
       "\t 1         & 1         & 0.503     & 0.523     & 0.503     & 9         &  0        & 1         & 2         & 397       &  5        & 1950      & 1         & 1         & 0.5898832\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | caste | mathematics_marks | english_marks | science_marks | science_teacher | languages_teacher | guardian | internet | total_students | total_toilets | establishment_year | continue_drop | xgboost_prediction | xgboost_probability | \n",
       "|---|---|---|---|---|---|\n",
       "| 1         | 1         | 0.290     | 0.512     | 0.290     | 4         |  7        | 3         | 2         | 356       | 14        | 1943      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 2         | 0.602     | 0.666     | 0.602     | 4         |  2        | 3         | 1         | 179       |  8        | 1955      | 0         | 0         | 0.4060442 | \n",
       "| 1         | 1         | 0.594     | 0.519     | 0.594     | 4         |  8        | 3         | 2         | 335       | 43        | 1916      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 1         | 0.461     | 0.524     | 0.461     | 0         |  3        | 3         | 2         | 469       | 14        | 1905      | 0         | 0         | 0.4060442 | \n",
       "| 1         | 2         | 0.742     | 0.672     | 0.742     | 3         | 12        | 3         | 2         | 132       | 14        | 1996      | 0         | 0         | 0.4057302 | \n",
       "| 1         | 1         | 0.503     | 0.523     | 0.503     | 9         |  0        | 1         | 2         | 397       |  5        | 1950      | 1         | 1         | 0.5898832 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender caste mathematics_marks english_marks science_marks science_teacher\n",
       "1 1      1     0.290             0.512         0.290         4              \n",
       "2 1      2     0.602             0.666         0.602         4              \n",
       "3 1      1     0.594             0.519         0.594         4              \n",
       "4 1      1     0.461             0.524         0.461         0              \n",
       "5 1      2     0.742             0.672         0.742         3              \n",
       "6 1      1     0.503             0.523         0.503         9              \n",
       "  languages_teacher guardian internet total_students total_toilets\n",
       "1  7                3        2        356            14           \n",
       "2  2                3        1        179             8           \n",
       "3  8                3        2        335            43           \n",
       "4  3                3        2        469            14           \n",
       "5 12                3        2        132            14           \n",
       "6  0                1        2        397             5           \n",
       "  establishment_year continue_drop xgboost_prediction xgboost_probability\n",
       "1 1943               0             0                  0.4057302          \n",
       "2 1955               0             0                  0.4060442          \n",
       "3 1916               0             0                  0.4057302          \n",
       "4 1905               0             0                  0.4060442          \n",
       "5 1996               0             0                  0.4057302          \n",
       "6 1950               1             1                  0.5898832          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score model\n",
    "\n",
    "predictions <- predict(m.xgb, dtest$data)\n",
    "threshold <- 0.5\n",
    "xgboost_probability <- predictions\n",
    "xgboost_prediction <- ifelse(xgboost_probability > threshold, 1, 0)\n",
    "pred <- cbind(testdata, dtest$label, xgboost_prediction, xgboost_probability)\n",
    "names(pred)[names(pred) == \"dtest$label\"] <- target\n",
    "head(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Predicted\n",
      "Observed    0    1\n",
      "       0 5475    0\n",
      "       1    0  255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Precision</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>Recall</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>F-Score</dt>\n",
       "\t\t<dd>1</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 1\n",
       "\\item[Precision] 1\n",
       "\\item[Recall] 1\n",
       "\\item[F-Score] 1\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   1Precision\n",
       ":   1Recall\n",
       ":   1F-Score\n",
       ":   1\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy Precision    Recall   F-Score \n",
       "        1         1         1         1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call.graphics(L_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAXVBMVEUAAAAzMzNHR0dNTU1g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\nkUQCQiSRgBBJJCD/H/XeV140I+uZAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "\n",
    "metrics.xgb <- evaluateModel(data=pred,\n",
    "                             observed=\"continue_drop\",\n",
    "                             predicted=\"xgboost_prediction\")\n",
    "metrics.xgb\n",
    "\n",
    "rocChart(pr=pred$xgboost_probability, target=pred$continue_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Finish Up - Save Model\n",
    "\n",
    "We save the model, together with the dataset and other variables, into a binary R file. Here, we use xgboost model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'models/studentDropIndia_xgboost_20170808_191534.RData'"
      ],
      "text/latex": [
       "'models/studentDropIndia\\_xgboost\\_20170808\\_191534.RData'"
      ],
      "text/markdown": [
       "'models/studentDropIndia_xgboost_20170808_191534.RData'"
      ],
      "text/plain": [
       "[1] \"models/studentDropIndia_xgboost_20170808_191534.RData\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- m.xgb\n",
    "mtype <- 'xgboost'\n",
    "pr <- xgboost_probability\n",
    "cl <- xgboost_prediction\n",
    "\n",
    "dname <- \"models\"\n",
    "if (! file.exists(dname)) dir.create(dname)\n",
    "time.stamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")\n",
    "fstem <- paste(dsname, mtype, time.stamp, sep=\"_\")\n",
    "(fname <- file.path(dname, sprintf(\"%s.RData\", fstem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(ds, dsname, vars, target, ignore,\n",
    "form, nobs, seed, train, test, model, mtype, pr, cl,\n",
    "file=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load this later and replicate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "attributes": {
     "classes": [],
     "error": "FALSE",
     "id": "",
     "message": "FALSE,",
     "warning": "FALSE,"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ds'</li>\n",
       "\t<li>'dsname'</li>\n",
       "\t<li>'vars'</li>\n",
       "\t<li>'target'</li>\n",
       "\t<li>'ignore'</li>\n",
       "\t<li>'form'</li>\n",
       "\t<li>'nobs'</li>\n",
       "\t<li>'seed'</li>\n",
       "\t<li>'train'</li>\n",
       "\t<li>'test'</li>\n",
       "\t<li>'model'</li>\n",
       "\t<li>'mtype'</li>\n",
       "\t<li>'pr'</li>\n",
       "\t<li>'cl'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ds'\n",
       "\\item 'dsname'\n",
       "\\item 'vars'\n",
       "\\item 'target'\n",
       "\\item 'ignore'\n",
       "\\item 'form'\n",
       "\\item 'nobs'\n",
       "\\item 'seed'\n",
       "\\item 'train'\n",
       "\\item 'test'\n",
       "\\item 'model'\n",
       "\\item 'mtype'\n",
       "\\item 'pr'\n",
       "\\item 'cl'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ds'\n",
       "2. 'dsname'\n",
       "3. 'vars'\n",
       "4. 'target'\n",
       "5. 'ignore'\n",
       "6. 'form'\n",
       "7. 'nobs'\n",
       "8. 'seed'\n",
       "9. 'train'\n",
       "10. 'test'\n",
       "11. 'model'\n",
       "12. 'mtype'\n",
       "13. 'pr'\n",
       "14. 'cl'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"ds\"     \"dsname\" \"vars\"   \"target\" \"ignore\" \"form\"   \"nobs\"   \"seed\"  \n",
       " [9] \"train\"  \"test\"   \"model\"  \"mtype\"  \"pr\"     \"cl\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(load(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by using generic variable names we can load different model files and perform common operations on them without changing the names within a script. However, do note that each time we load such a saved model file we overwrite any other variables of the same name."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
